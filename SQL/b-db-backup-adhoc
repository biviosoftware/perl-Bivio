#!/bin/sh
#
# $Id$
#
# b-db-backup-adhoc [[db-login] [[db-name] [[backup-host] [transfer-host]]]]
#

DB_LOGIN=${1:-bivio/bivio}
DB_NAME=${2:-PROD}
BACKUP_HOST=${3:-carve}
TRANSFER_HOST=${4:-locker}

HOST=`hostname`
HOST=`expr $HOST : '\([^\.]*\)\.' '|' $HOST`

. /etc/ssh2/ssh2_agent

ts=$(date +%Y%m%d%H%M%S)
cd /home/bkp
mkdir $ts
cd $ts

# DON'T backup lock_t, because it is temporal.
# Consistent
/usr/local/oracle/product/8.1.5/bin/exp ${DB_LOGIN}@$DB_NAME grants=n compress=y indexes=n rows=y constraints=n statistics=none feedback=0 consistent=y file=./$ts-realm.dmp 'tables=(ACCOUNTING_IMPORT_T,ADDRESS_T,CLUB_T,CONNECT_SURVEY_T,DB_UPGRADE_T,EMAIL_T,ENTRY_T,FILE_QUOTA_T,FILE_T,INSTITUTION_T,INSTRUMENT_T,JAPAN_SURVEY_T,MAIL_MESSAGE_T,MEMBER_ENTRY_T,PHONE_T,PREFERENCES_T,REALM_ACCOUNT_ENTRY_T,REALM_ACCOUNT_T,REALM_INSTRUMENT_ENTRY_T,REALM_INSTRUMENT_T,REALM_INSTRUMENT_VALUATION_T,REALM_INVITE_T,REALM_OWNER_T,REALM_ROLE_T,REALM_TRANSACTION_T,REALM_USER_T,USER_T,TAX_ID_T)'

# Is consistent with above, but we might lose the last messages not
# in the database.  Easy to check.
echo httpd
tar czf - /home/httpd > $ts-$HOST-httpd.tgz

# Not consistent, because we only update once per day
/usr/local/oracle/product/8.1.5/bin/exp ${DB_LOGIN}@$DB_NAME grants=n compress=y indexes=n rows=y constraints=n statistics=none feedback=0 consistent=n file=./$ts-mgfs.dmp 'tables=(MGFS_BALANCE_SHEET_T,MGFS_CASH_FLOW_T,MGFS_COMPANY_BOARD_T,MGFS_COMPANY_SEGMENT_T,MGFS_COMPANY_T,MGFS_DAILY_QUOTE_T,MGFS_DOWNLOAD_T,MGFS_FUNDAMENTAL_T,MGFS_INCOME_STATEMENT_T,MGFS_INSTRUMENT_T,MGFS_SECONDARY_SIC_T,MGFS_SIC_CODE_T,MGFS_SPLIT_T,MGFS_SP_INDUSTRY_T,INSTRUMENT_T)'

echo dbs-admin
tar czf - /usr/local/oracle/product/8.1.5/dbs /usr/local/oracle/product/8.1.5/admin /usr/local/oracle/product/8.1.5/network/admin >$ts-$HOST-dbs-admin.tgz

echo reqng
/usr/local/bin/ssh ${BACKUP_HOST} tar czf - /usr/local/reqng >$ts-${BACKUP_HOST}-reqng.tgz 
/usr/local/bin/ssh ${BACKUP_HOST} tar czf - /home/httpd >$ts-${BACKUP_HOST}-httpd.tgz 

echo Compressing *mgfs.dmp
gzip *mgfs.dmp
echo Compressing *realm.dmp
gzip *realm.dmp

cd ..

echo "$(date +"%m/%d/%y") tar 200b $ts" >> TAPE
cp TAPE $ts
ssh ${BACKUP_HOST} "[ -d /home/bkp/$DB_NAME ] || mkdir /home/bkp/$DB_NAME"
scp -pr $ts ${BACKUP_HOST}:/home/bkp/$DB_NAME

echo Writing to tape on ${BACKUP_HOST}
/usr/local/bin/ssh ${BACKUP_HOST} tar cbf 200b /dev/tape /home/bkp/$DB_NAME/$ts

echo Transferring to ${TRANSFER_HOST}
ssh ${BACKUP_HOST} "scp -pr /home/bkp/$DB_NAME/$ts ${TRANSFER_HOST}:/home/bkp/$DB_NAME"

# Keep a few days worth of backup online
cd ..
thin=`ls -dt [0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9] | tail +$THIN_DAYS`
if [ "$thin" ]; then
    echo Removing $thin
    rm -rf $thin
fi
